# Lunar Crater Detection Using YOLOv11

## Project Overview
This project implements an automated lunar crater detection system using a custom YOLOv11 object detection model. The goal is to identify and localize craters in high-resolution lunar surface imagery. The pipeline includes:
- Loading a pretrained/custom YOLOv11 model (`best.pt`).
- Performing inference on full images and sliding-window tiled images.
- Applying non-maximum suppression (NMS) to merge overlapping detections.
- Visualizing and saving annotated output images with bounding boxes and confidence scores.

## Table of Contents
1. [Prerequisites](#prerequisites)  
2. [Installation](#installation)  
3. [Project Structure](#project-structure)  
4. [Usage](#usage)  
   - [Single-Image Inference](#single-image-inference)  
   - [Sliding-Window Inference](#sliding-window-inference)  
5. [Code Explanation](#code-explanation)  
   - [Loading the Model](#loading-the-model)  
   - [Inference Parameters](#inference-parameters)  
   - [Drawing Bounding Boxes](#drawing-bounding-boxes)  
   - [Sliding-Window Approach](#sliding-window-approach)  
   - [Non-Maximum Suppression (NMS)](#non-maximum-suppression-nms)  
6. [Outputs](#outputs)  
7. [Troubleshooting](#troubleshooting)  
8. [Acknowledgments](#acknowledgments)  
9. [License](#license)

---

## Prerequisites
- **Python 3.8+**
- **CUDA-compatible GPU** (optional but recommended for faster inference)
- Installed system packages:  
  - `git`
  - `ffmpeg` (if using video inputs / outputs)

## Installation

1. **Clone the Repository (optional)**  
   If you have your code in a Git repository, clone it. Otherwise, create a project directory:
   ```bash
   mkdir lunar-crater-detection
   cd lunar-crater-detection
````

2. **Create and Activate a Virtual Environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install Python Dependencies**
   Make sure you have `pip` updated:

   ```bash
   pip install --upgrade pip
   ```

   Install required libraries:

   ```bash
   pip install ultralytics torch torchvision opencv-python matplotlib
   ```

4. **Obtain the Pretrained/Custom Model**
   Place your `best.pt` (YOLOv11 weights) file into a folder called `models/`:

   ```
   models/
   └── best.pt
   ```

5. **Prepare Test Images**
   Create an `images/` directory and add your lunar test images (e.g., `.jpg`, `.png`):

   ```
   images/
   └── test_image1.jpg
   └── test_image2.png
   ```

---

## Project Structure

```
lunar-crater-detection/
├── models/
│   └── best.pt               # YOLOv11 model weights
├── images/                    # Input lunar surface images
│   └── test_image1.jpg
├── outputs/                   # Generated annotated images
│   └── crater_detected.jpg
│   └── crater_detected_sliding_window.jpg
├── inference_single.py        # Single-image inference script
├── inference_sliding.py       # Sliding-window inference script
├── requirements.txt           # Lockfile of dependencies
└── README.md                  # This README
```

* **models/best.pt**: Trained YOLOv11 weights for crater detection.
* **images/**: Folder containing input test images.
* **outputs/**: Folder where annotated images are saved.
* **inference\_single.py**: Python script for single-image inference.
* **inference\_sliding.py**: Python script for tiled (sliding-window) inference + NMS.
* **requirements.txt**: Generated by `pip freeze > requirements.txt` to track exact versions.

---

## Usage

Before running any script, ensure your virtual environment is activated and you have placed `best.pt` in `models/`.

### Single-Image Inference

1. **Command**

   ```bash
   python3 inference_single.py --model-path models/best.pt --image-path images/test_image1.jpg --output-path outputs/crater_detected.jpg
   ```

2. **Options**

   * `--model-path`: Path to the YOLOv11 weights (`.pt` file).
   * `--image-path`: Path to the input image.
   * `--output-path`: Path where the annotated output will be saved.

3. **Example Output**

   * The script will print the number of craters detected and save an annotated image with bounding boxes and confidence scores to `outputs/`.

### Sliding-Window Inference

For very large lunar images (e.g., > 2000×2000 pixels), a sliding-window (tiled) approach helps maintain detection accuracy without downscaling too heavily.

1. **Command**

   ```bash
   python3 inference_sliding.py \
     --model-path models/best.pt \
     --image-path images/high_res_lunar.png \
     --output-path outputs/crater_detected_sliding_window.jpg \
     --tile-size 1024 \
     --stride 512 \
     --conf-thres 0.09 \
     --iou-nms 0.30
   ```

2. **Options**

   * `--model-path`: Path to the YOLOv11 weights (`.pt` file).
   * `--image-path`: Path to the large input image.
   * `--output-path`: Path where the final annotated image will be saved.
   * `--tile-size`: Size of each tile/crop in pixels (default: 1024).
   * `--stride`: Overlap between adjacent tiles (default: 512).
   * `--conf-thres`: Confidence threshold for raw detections before NMS (default: 0.12).
   * `--iou-nms`: IoU threshold for non-maximum suppression on aggregated detections (default: 0.30).

3. **Example Output**

   * The script prints the total number of craters detected (after merging with NMS) and saves an annotated image to `outputs/`.

---

## Code Explanation

Below is a high-level walkthrough of the two main scripts:

### 1. Loading the Model

```python
from ultralytics import YOLO
model = YOLO(model_path)
```

* Uses the Ultralytics YOLOv11 API (`ultralytics` package).
* Loads the `best.pt` weights into a YOLO object for inference.

### 2. Inference Parameters

* **Confidence Threshold (`conf`)**:
  Minimum confidence score for a detection to be considered. A lower value (e.g., 0.02–0.12) retains more candidates but may include false positives.
* **IoU Threshold (`iou`)**:
  Controls how aggressively boxes are merged within a single tile.
* **imgsz**:
  The pixel size to which each tile (or the single image) is resized for inference (e.g., 640 or 1024).

### 3. Drawing Bounding Boxes

```python
for box, score in zip(boxes.xyxy, boxes.conf):
    x1, y1, x2, y2 = map(int, box.tolist())
    cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(annotated_img, f"{score*100:.1f}%", (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
```

* Iterates over each detected bounding box (`xyxy`) and its confidence score (`conf`).
* Draws a green rectangle and places the confidence percentage above the top-left corner.

### 4. Sliding-Window Approach

```python
tile_size = 1024
stride = 512

for y in range(0, original_h, stride):
    for x in range(0, original_w, stride):
        tile = original_img[y:y + tile_size, x:x + tile_size]
        results = model.predict(tile, imgsz=640, conf=conf_thres, iou=0.4)
        # Shift coordinates back to full image and collect boxes, scores, classes
```

* **Tile Generation**: Crops the large image into overlapping tiles of size `tile_size × tile_size`.
* **Overlap (Stride)**: By sliding the window with a stride less than `tile_size`, regions overlap, ensuring no crater is missed at tile edges.

### 5. Non-Maximum Suppression (NMS)

After collecting all raw detections across tiles:

```python
all_boxes = torch.tensor(all_boxes)
all_scores = torch.tensor(all_scores)

indices = nms(all_boxes, all_scores, iou_nms)

final_boxes = all_boxes[indices]
final_scores = all_scores[indices]
```

* Converts the list of all bounding boxes and scores into PyTorch tensors.
* Applies NMS to suppress overlapping boxes (based on `iou_nms`), retaining only the highest-confidence detections.

---

## Outputs

* **Single-Image Mode**:

  * `crater_detected.jpg` (or user-specified name) with bounding boxes and confidence scores overlaid.
  * Console output:

    ```
    Number of craters detected: <N>
    Annotated image saved to: outputs/crater_detected.jpg
    ```

* **Sliding-Window Mode**:

  * `crater_detected_sliding_window.jpg` (or specified name) with final merged detections.
  * Console output:

    ```
    Number of craters detected after sliding window NMS: <M>
    ```

---

## Troubleshooting

* **“Model path does not exist”**:

  * Verify that `models/best.pt` exists. Use the exact path when calling the script.

* **“Failed to load image”**:

  * Confirm that the image file exists and is not corrupted. Supported formats: `.jpg`, `.png`, `.jpeg`, etc.

* **CUDA Out of Memory**:

  * Reduce `imgsz` (e.g., from 1024 to 640) or lower `tile-size`.
  * Run on CPU by forcing `device='cpu'`, but inference may be slower.

* **No Detections / Too Many False Positives**:

  * Adjust `--conf-thres` higher to filter low-confidence detections.
  * Tweak `--iou-nms` to balance box merging.
  * If using a custom model, verify the training dataset and hyperparameters.

---

## Acknowledgments

* **Ultralytics YOLO**: [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
* **PyTorch**: [https://pytorch.org/](https://pytorch.org/)
* **OpenCV**: [https://opencv.org/](https://opencv.org/)
* **Matplotlib**: [https://matplotlib.org/](https://matplotlib.org/)

This project architecture and code structure were inspired by best practices from various object detection repositories and the lunar crater detection community.

---

## License

This project is released under the MIT License. See `LICENSE` file for details.
EOF

```
```
